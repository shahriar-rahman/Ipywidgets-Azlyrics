{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27dc92d7",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Lucida Sans Unicode; color:#a10a0a; font-size: 25px\"> Scrape Album from Artists </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f70bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%run py_utils/scraping_utils.ipynb\n",
    "%run py_utils/generic_utils.ipynb\n",
    "%run py_utils/sqlite_utils.ipynb\n",
    "\n",
    "def get_albums(start_urls):\n",
    "    album_dict = {}    \n",
    "    a_key = 'a'\n",
    "    div_key = 'div'\n",
    "    artist_key = 'title'\n",
    "    href_attr = {'class': 'listalbum-item'}\n",
    "    album_attr = {'class': 'album'}\n",
    "    tracks_table = {'id': 'listAlbum'}\n",
    "    album_class = ['album']\n",
    "    track_class = ['listalbum-item']\n",
    "    root_url = \"https://www.azlyrics.com\"  \n",
    "    \n",
    "    for url in start_urls:\n",
    "        print(\">> Scraping {}\".format(url))\n",
    "        soup = get_request(url)        \n",
    "        try:\n",
    "            parse_table = bs4_scrape(soup, 'find', div_key, tracks_table)\n",
    "            parse_list = bs4_scrape(parse_table, 'findAll', div_key)    \n",
    "\n",
    "        except Exception as exc:\n",
    "            print('! Exception: {}'.format(exc))\n",
    "            single_list = bs4_scrape(soup, 'findAll', div_key, href_attr)\n",
    "            parse_list = [item for item in single_list]\n",
    "            \n",
    "        artist_name = ' '.join(bs4_scrape(soup, 'find', artist_key).text.split(' ')[:-1])        \n",
    "        album_name = []; album_year = []; track_name = []; track_url = []           \n",
    "        get_album = ''; get_year = '' \n",
    "        \n",
    "        for row in parse_list:  \n",
    "            get_class = row.get('class') \n",
    "            \n",
    "            if get_class == album_class: \n",
    "                try: \n",
    "                    get_album = ' '.join(row.text.split(' ')[:-1]).replace('\"', '')  \n",
    "                    get_year = int(''.join(row.text.split(' ')[-1]).replace('(','').replace(')',''))\n",
    "                    \n",
    "                except Exception as exc: \n",
    "                    print(\"! ValueError: {}\".format(exc))\n",
    "                    get_year = ''\n",
    "                                \n",
    "            elif get_class == track_class:\n",
    "                track_name.append(row.text)\n",
    "                track_url.append((lambda url: root_url+url if root_url not in url else url)\n",
    "                    ((lambda url_tag: url_tag.get('href') if url_tag is not None else '')(bs4_scrape(row, 'find', a_key))))\n",
    "                \n",
    "                album_name.append(get_album if get_album != '' else 'other')\n",
    "                album_year.append(get_year if get_year != '' else np.nan)\n",
    "            \n",
    "        \n",
    "        album_dict[artist_name] = {'track_names': track_name, 'track_urls': track_url, \n",
    "                                   'album_names': album_name, 'album_years':album_year}\n",
    "    return album_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
